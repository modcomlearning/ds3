{
    "cells": [
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#  CLassification Example\nimport pandas \nflowers  = pandas.read_csv(\"https://modkenya.com/datascience/datasets/iris.csv\")\nflowers",
            "execution_count": 1,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 1,
                    "data": {
                        "text/plain": "     sepallength  sepalwidth  petallength  petalwidth           class\n0            5.1         3.5          1.4         0.2     Iris-setosa\n1            4.9         3.0          1.4         0.2     Iris-setosa\n2            4.7         3.2          1.3         0.2     Iris-setosa\n3            4.6         3.1          1.5         0.2     Iris-setosa\n4            5.0         3.6          1.4         0.2     Iris-setosa\n..           ...         ...          ...         ...             ...\n145          6.7         3.0          5.2         2.3  Iris-virginica\n146          6.3         2.5          5.0         1.9  Iris-virginica\n147          6.5         3.0          5.2         2.0  Iris-virginica\n148          6.2         3.4          5.4         2.3  Iris-virginica\n149          5.9         3.0          5.1         1.8  Iris-virginica\n\n[150 rows x 5 columns]",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepallength</th>\n      <th>sepalwidth</th>\n      <th>petallength</th>\n      <th>petalwidth</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>6.7</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.3</td>\n      <td>Iris-virginica</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>6.3</td>\n      <td>2.5</td>\n      <td>5.0</td>\n      <td>1.9</td>\n      <td>Iris-virginica</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>6.5</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.0</td>\n      <td>Iris-virginica</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>6.2</td>\n      <td>3.4</td>\n      <td>5.4</td>\n      <td>2.3</td>\n      <td>Iris-virginica</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>5.9</td>\n      <td>3.0</td>\n      <td>5.1</td>\n      <td>1.8</td>\n      <td>Iris-virginica</td>\n    </tr>\n  </tbody>\n</table>\n<p>150 rows \u00d7 5 columns</p>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "print(flowers.isnull().sum())",
            "execution_count": 2,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "sepallength    0\nsepalwidth     0\npetallength    0\npetalwidth     0\nclass          0\ndtype: int64\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Step 1 - split into input and outputs\narray = flowers.values\nX = array[:, 0:4]  # NB: there is a minus 1, 4 is not counted here\nY = array[:, 4]\n\n\n# Step 2: split X, Y into 2 parts , training/testing\nfrom sklearn import model_selection\nX_train, X_test, Y_train, Y_test = model_selection.train_test_split(X,Y, test_size = 0.30, random_state=42)\n\n\n\n# Step 3: modeling\n# Decision trees, Random forest, KNN, SVM, Gaussian, Logistic Models, \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier()\nmodel.fit(X_train, Y_train)\n# we do not fit the X_test and Y_test...\n\n\n# Remember that we have X_test and Y_test not exposed to the model\n# Ask the model to predict X_test as you hide the Y_test - classes\npredictions = model.predict(X_test)\n\nprint(predictions)\nprint('====')\nprint(Y_test)\n\n\nfrom sklearn.metrics import accuracy_score\n# Compare the model predictiosn and your Y_test\nprint(accuracy_score(Y_test, predictions))\n\n# Last step use your flower\nnewflower = [[5.8, 2.5, 4.2, 3.6]]\nprint(model.predict(newflower))\n\n",
            "execution_count": 3,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "['Iris-versicolor' 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor'\n 'Iris-versicolor' 'Iris-setosa' 'Iris-versicolor' 'Iris-virginica'\n 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica' 'Iris-setosa'\n 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor'\n 'Iris-virginica' 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica'\n 'Iris-setosa' 'Iris-virginica' 'Iris-setosa' 'Iris-virginica'\n 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor'\n 'Iris-setosa' 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor'\n 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-virginica'\n 'Iris-versicolor' 'Iris-versicolor' 'Iris-setosa' 'Iris-setosa']\n====\n['Iris-versicolor' 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor'\n 'Iris-versicolor' 'Iris-setosa' 'Iris-versicolor' 'Iris-virginica'\n 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica' 'Iris-setosa'\n 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor'\n 'Iris-virginica' 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica'\n 'Iris-setosa' 'Iris-virginica' 'Iris-setosa' 'Iris-virginica'\n 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor'\n 'Iris-setosa' 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor'\n 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-virginica'\n 'Iris-versicolor' 'Iris-versicolor' 'Iris-setosa' 'Iris-setosa']\n1.0\n['Iris-versicolor']\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Example 2 clasification\nimport pandas \npima  = pandas.read_csv(\"https://modkenya.com/datascience/datasets/pima.csv\")\npima\n\n# 0 - Negative\n# 1 - Positive",
            "execution_count": 4,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 4,
                    "data": {
                        "text/plain": "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n0              6      148             72             35        0  33.6   \n1              1       85             66             29        0  26.6   \n2              8      183             64              0        0  23.3   \n3              1       89             66             23       94  28.1   \n4              0      137             40             35      168  43.1   \n..           ...      ...            ...            ...      ...   ...   \n763           10      101             76             48      180  32.9   \n764            2      122             70             27        0  36.8   \n765            5      121             72             23      112  26.2   \n766            1      126             60              0        0  30.1   \n767            1       93             70             31        0  30.4   \n\n     DiabetesPedigreeFunction  Age  Outcome  \n0                       0.627   50        1  \n1                       0.351   31        0  \n2                       0.672   32        1  \n3                       0.167   21        0  \n4                       2.288   33        1  \n..                        ...  ...      ...  \n763                     0.171   63        0  \n764                     0.340   27        0  \n765                     0.245   30        0  \n766                     0.349   47        1  \n767                     0.315   23        0  \n\n[768 rows x 9 columns]",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>148</td>\n      <td>72</td>\n      <td>35</td>\n      <td>0</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>85</td>\n      <td>66</td>\n      <td>29</td>\n      <td>0</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>183</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>89</td>\n      <td>66</td>\n      <td>23</td>\n      <td>94</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>137</td>\n      <td>40</td>\n      <td>35</td>\n      <td>168</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>763</th>\n      <td>10</td>\n      <td>101</td>\n      <td>76</td>\n      <td>48</td>\n      <td>180</td>\n      <td>32.9</td>\n      <td>0.171</td>\n      <td>63</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>764</th>\n      <td>2</td>\n      <td>122</td>\n      <td>70</td>\n      <td>27</td>\n      <td>0</td>\n      <td>36.8</td>\n      <td>0.340</td>\n      <td>27</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>765</th>\n      <td>5</td>\n      <td>121</td>\n      <td>72</td>\n      <td>23</td>\n      <td>112</td>\n      <td>26.2</td>\n      <td>0.245</td>\n      <td>30</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>766</th>\n      <td>1</td>\n      <td>126</td>\n      <td>60</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.1</td>\n      <td>0.349</td>\n      <td>47</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>767</th>\n      <td>1</td>\n      <td>93</td>\n      <td>70</td>\n      <td>31</td>\n      <td>0</td>\n      <td>30.4</td>\n      <td>0.315</td>\n      <td>23</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>768 rows \u00d7 9 columns</p>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "print(pima.isnull().sum())",
            "execution_count": 5,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Pregnancies                 0\nGlucose                     0\nBloodPressure               0\nSkinThickness               0\nInsulin                     0\nBMI                         0\nDiabetesPedigreeFunction    0\nAge                         0\nOutcome                     0\ndtype: int64\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "print(pima.corr())",
            "execution_count": 6,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "                          Pregnancies   Glucose  BloodPressure  SkinThickness  \\\nPregnancies                  1.000000  0.129459       0.141282      -0.081672   \nGlucose                      0.129459  1.000000       0.152590       0.057328   \nBloodPressure                0.141282  0.152590       1.000000       0.207371   \nSkinThickness               -0.081672  0.057328       0.207371       1.000000   \nInsulin                     -0.073535  0.331357       0.088933       0.436783   \nBMI                          0.017683  0.221071       0.281805       0.392573   \nDiabetesPedigreeFunction    -0.033523  0.137337       0.041265       0.183928   \nAge                          0.544341  0.263514       0.239528      -0.113970   \nOutcome                      0.221898  0.466581       0.065068       0.074752   \n\n                           Insulin       BMI  DiabetesPedigreeFunction  \\\nPregnancies              -0.073535  0.017683                 -0.033523   \nGlucose                   0.331357  0.221071                  0.137337   \nBloodPressure             0.088933  0.281805                  0.041265   \nSkinThickness             0.436783  0.392573                  0.183928   \nInsulin                   1.000000  0.197859                  0.185071   \nBMI                       0.197859  1.000000                  0.140647   \nDiabetesPedigreeFunction  0.185071  0.140647                  1.000000   \nAge                      -0.042163  0.036242                  0.033561   \nOutcome                   0.130548  0.292695                  0.173844   \n\n                               Age   Outcome  \nPregnancies               0.544341  0.221898  \nGlucose                   0.263514  0.466581  \nBloodPressure             0.239528  0.065068  \nSkinThickness            -0.113970  0.074752  \nInsulin                  -0.042163  0.130548  \nBMI                       0.036242  0.292695  \nDiabetesPedigreeFunction  0.033561  0.173844  \nAge                       1.000000  0.238356  \nOutcome                   0.238356  1.000000  \n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "print(pima.describe())",
            "execution_count": 7,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\ncount   768.000000  768.000000     768.000000     768.000000  768.000000   \nmean      3.845052  120.894531      69.105469      20.536458   79.799479   \nstd       3.369578   31.972618      19.355807      15.952218  115.244002   \nmin       0.000000    0.000000       0.000000       0.000000    0.000000   \n25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n75%       6.000000  140.250000      80.000000      32.000000  127.250000   \nmax      17.000000  199.000000     122.000000      99.000000  846.000000   \n\n              BMI  DiabetesPedigreeFunction         Age     Outcome  \ncount  768.000000                768.000000  768.000000  768.000000  \nmean    31.992578                  0.471876   33.240885    0.348958  \nstd      7.884160                  0.331329   11.760232    0.476951  \nmin      0.000000                  0.078000   21.000000    0.000000  \n25%     27.300000                  0.243750   24.000000    0.000000  \n50%     32.000000                  0.372500   29.000000    0.000000  \n75%     36.600000                  0.626250   41.000000    1.000000  \nmax     67.100000                  2.420000   81.000000    1.000000  \n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!pip install imblearn",
            "execution_count": 8,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Requirement already satisfied: imblearn in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (0.0)\nRequirement already satisfied: imbalanced-learn in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from imblearn) (0.7.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (0.16.0)\nRequirement already satisfied: scikit-learn>=0.23 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (0.23.1)\nRequirement already satisfied: numpy>=1.13.3 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.18.5)\nRequirement already satisfied: scipy>=0.19.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from scikit-learn>=0.23->imbalanced-learn->imblearn) (2.1.0)\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# step 1\narray = pima.values\nX = array[:, 0:8]\nY = array[:,8]\n\n\n\n\n# Feature Elimination\nfrom sklearn.feature_selection import RFE\nfrom sklearn.ensemble import RandomForestClassifier\nrandom_forest = RandomForestClassifier()\n# now use RFE with random forest\nrfe = RFE(random_forest, 5)\n\nrfe_fit = rfe.fit(X,Y)\n\nprint('Number of features', rfe_fit.n_features_)\nprint('Top  4 features affecting outcome', rfe_fit.support_)\n\n\n\n# we learnt that we have fewer Positives than , negatives\n# We syntetic data to oversample the positives\nfrom imblearn.over_sampling import SMOTE\nsmote = SMOTE(random_state=42)\nX_new, Y_new = smote.fit_sample(X, Y)\n\n\n# Step 2: split X, Y into 2 parts , training/testing\nfrom sklearn import model_selection\nX_train, X_test, Y_train, Y_test = model_selection.train_test_split(X_new,Y_new, test_size = 0.40, random_state=42)\n\n\n# step 3\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n# Spot Check Algorithms\nmodels = []\nmodels.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC(gamma='auto')))\nmodels.append(('GB', GradientBoostingClassifier()))\n# evaluate each model in turn\n\nfor name, model in models:\n      kfold = model_selection.KFold(n_splits=10, random_state=42, shuffle=True)\n      cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n      print(name, cv_results.mean())\n\n\n",
            "execution_count": 14,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass n_features_to_select=5 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n  FutureWarning)\n",
                    "name": "stderr"
                },
                {
                    "output_type": "stream",
                    "text": "Number of features 5\nTop  4 features affecting outcome [False  True  True False False  True  True  True]\nLR 0.7416666666666667\nLDA 0.74\nKNN 0.7416666666666667\nCART 0.7516666666666667\nNB 0.7266666666666667\nSVM 0.635\nGB 0.8133333333333335\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "model =GradientBoostingClassifier()\nmodel.fit(X_train,Y_train)\n\n# ask the model to predict the xtest as you hide the y -test\npredictions = model.predict(X_test)\n#print('Predicted Outcome', predictions)\n#print('Expected Outcome ', Y_test)\n\n\n# check accuracy score\nfrom sklearn.metrics import accuracy_score\nprint(accuracy_score(Y_test, predictions))\n\n\nfrom sklearn.metrics import classification_report\nprint(classification_report(Y_test, predictions))\n\n\n\n\nnewpatient = [[3, 130, 36, 39, 5, 33.6, 0.627, 55]]\nprint(model.predict(newpatient))\n\n",
            "execution_count": 15,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "0.77\n              precision    recall  f1-score   support\n\n         0.0       0.80      0.72      0.76       203\n         1.0       0.74      0.82      0.78       197\n\n    accuracy                           0.77       400\n   macro avg       0.77      0.77      0.77       400\nweighted avg       0.77      0.77      0.77       400\n\n[1.]\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.7.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}